{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enviroment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Torch with CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# print(torch.cuda.is_available())  # Should return True if GPU is available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gdown -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell might take more than 1 minute to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import gdown\n",
    "# import zipfile\n",
    "\n",
    "# # URL of the zip file on Google Drive\n",
    "# url = 'https://drive.google.com/file/d/1OXoi4UeZy726ILuPM6Y57sr4eZhqrhq2/view?usp=sharing'\n",
    "\n",
    "# # Function to download the zip file and extract it\n",
    "# def download_and_extract_zip(url, extract_to='PlantVillage'):\n",
    "#     # Generate the direct download URL for the file\n",
    "#     file_id = url.split('/d/')[1].split('/')[0]\n",
    "#     download_url = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "#     # Download the zip file\n",
    "#     zip_file = 'PlantVillage.zip'\n",
    "#     gdown.download(download_url, zip_file, quiet=False)\n",
    "\n",
    "#     # Extract the zip file directly\n",
    "#     with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "#         # Extract all the files directly into the 'extract_to' folder\n",
    "#         zip_ref.extractall(extract_to)\n",
    "\n",
    "#     # Remove the zip file after extraction\n",
    "#     os.remove(zip_file)\n",
    "\n",
    "# # Check if the 'PlantVillage' folder exists\n",
    "# if not os.path.exists('PlantVillage') or not os.listdir('PlantVillage'):\n",
    "#     download_and_extract_zip(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class to index mapping: {'Apple___Apple_scab': 0, 'Apple___Black_rot': 1, 'Apple___Cedar_apple_rust': 2, 'Apple___healthy': 3, 'Blueberry___healthy': 4, 'Cherry_(including_sour)___Powdery_mildew': 5, 'Cherry_(including_sour)___healthy': 6, 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot': 7, 'Corn_(maize)___Common_rust_': 8, 'Corn_(maize)___Northern_Leaf_Blight': 9, 'Corn_(maize)___healthy': 10, 'Grape___Black_rot': 11, 'Grape___Esca_(Black_Measles)': 12, 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 13, 'Grape___healthy': 14, 'Orange___Haunglongbing_(Citrus_greening)': 15, 'Peach___Bacterial_spot': 16, 'Peach___healthy': 17, 'Pepper,_bell___Bacterial_spot': 18, 'Pepper,_bell___healthy': 19, 'Potato___Early_blight': 20, 'Potato___Late_blight': 21, 'Potato___healthy': 22, 'Raspberry___healthy': 23, 'Soybean___healthy': 24, 'Squash___Powdery_mildew': 25, 'Strawberry___Leaf_scorch': 26, 'Strawberry___healthy': 27, 'Tomato___Bacterial_spot': 28, 'Tomato___Early_blight': 29, 'Tomato___Late_blight': 30, 'Tomato___Leaf_Mold': 31, 'Tomato___Septoria_leaf_spot': 32, 'Tomato___Spider_mites Two-spotted_spider_mite': 33, 'Tomato___Target_Spot': 34, 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 35, 'Tomato___Tomato_mosaic_virus': 36, 'Tomato___healthy': 37}\n",
      "                                                Class  Count\n",
      "0                                    Potato___healthy    121\n",
      "1                            Apple___Cedar_apple_rust    220\n",
      "2                                     Peach___healthy    288\n",
      "3                                 Raspberry___healthy    297\n",
      "4                        Tomato___Tomato_mosaic_virus    299\n",
      "5                                     Grape___healthy    339\n",
      "6                                Strawberry___healthy    364\n",
      "7   Corn_(maize)___Cercospora_leaf_spot Gray_leaf_...    410\n",
      "8                                   Apple___Black_rot    496\n",
      "9                                  Apple___Apple_scab    504\n",
      "10                  Cherry_(including_sour)___healthy    684\n",
      "11                                 Tomato___Leaf_Mold    761\n",
      "12                Corn_(maize)___Northern_Leaf_Blight    788\n",
      "13                      Pepper,_bell___Bacterial_spot    797\n",
      "14                               Potato___Late_blight    800\n",
      "15                              Potato___Early_blight    800\n",
      "16                              Tomato___Early_blight    800\n",
      "17           Cherry_(including_sour)___Powdery_mildew    842\n",
      "18         Grape___Leaf_blight_(Isariopsis_Leaf_Spot)    861\n",
      "19                           Strawberry___Leaf_scorch    887\n",
      "20                             Corn_(maize)___healthy    929\n",
      "21                                  Grape___Black_rot    944\n",
      "22                        Corn_(maize)___Common_rust_    953\n",
      "23                       Grape___Esca_(Black_Measles)   1107\n",
      "24                               Tomato___Target_Spot   1123\n",
      "25                             Pepper,_bell___healthy   1183\n",
      "26                                Blueberry___healthy   1202\n",
      "27                                   Tomato___healthy   1273\n",
      "28                                    Apple___healthy   1316\n",
      "29      Tomato___Spider_mites Two-spotted_spider_mite   1341\n",
      "30                        Tomato___Septoria_leaf_spot   1417\n",
      "31                            Squash___Powdery_mildew   1468\n",
      "32                               Tomato___Late_blight   1527\n",
      "33                            Tomato___Bacterial_spot   1702\n",
      "34                             Peach___Bacterial_spot   1838\n",
      "35                                  Soybean___healthy   4072\n",
      "36             Tomato___Tomato_Yellow_Leaf_Curl_Virus   4286\n",
      "37           Orange___Haunglongbing_(Citrus_greening)   4405\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Define transformations for your dataset\n",
    "image_width = 32\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_width, image_width)),  # Resize all images to 128x128\n",
    "    transforms.ToTensor(),          # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Load train dataset\n",
    "train_path = os.path.join('PlantVillage', 'train')\n",
    "train_dataset = datasets.ImageFolder(root=train_path, transform=transform)\n",
    "\n",
    "# Load val dataset\n",
    "val_path = os.path.join('PlantVillage', 'val')\n",
    "val_dataset = datasets.ImageFolder(root=val_path, transform=transform)\n",
    "\n",
    "# Split val dataset into val and test\n",
    "test_split = 0.5  # Use 50% of the current val set as the test set\n",
    "test_size = int(test_split * len(val_dataset))\n",
    "val_size = len(val_dataset) - test_size\n",
    "\n",
    "val_dataset, test_dataset = random_split(val_dataset, [val_size, test_size])\n",
    "\n",
    "# Create DataLoaders for train, val, and test datasets\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Function to count class instances with a progress bar\n",
    "def count_classes(dataset):\n",
    "    class_counter = Counter()\n",
    "    for _, label in tqdm(dataset, desc=\"Counting classes\"):\n",
    "        class_counter[label] += 1\n",
    "    return class_counter\n",
    "\n",
    "# Access class-to-index mapping\n",
    "class_to_idx = train_dataset.class_to_idx\n",
    "print(\"Class to index mapping:\", class_to_idx)\n",
    "\n",
    "def count_classes_in_folders(dataset_path):\n",
    "    \"\"\"\n",
    "    Count the number of items in each class folder in the dataset.\n",
    "    \"\"\"\n",
    "    class_counts = {}\n",
    "    for class_name in os.listdir(dataset_path):\n",
    "        class_folder = os.path.join(dataset_path, class_name)\n",
    "        if os.path.isdir(class_folder):  # Ensure it's a directory\n",
    "            class_counts[class_name] = len(os.listdir(class_folder))\n",
    "    return class_counts\n",
    "\n",
    "# Count classes\n",
    "train_class_counts = count_classes_in_folders(train_path)\n",
    "\n",
    "# Create a DataFrame from the train_class_counts dictionary\n",
    "class_df = pd.DataFrame(list(train_class_counts.items()), columns=[\"Class\", \"Count\"])\n",
    "\n",
    "# Sort the DataFrame by 'Count' in ascending order\n",
    "class_df_sorted = class_df.sort_values(by=\"Count\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Print the sorted DataFrame\n",
    "print(class_df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.optim as optim\n",
    "\n",
    "# # Model, loss function, optimizer\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available\n",
    "# num_classes = len(train_dataset.classes)\n",
    "# model = SimpleCNN(num_classes=num_classes, image_width=image_width).to(device)  # Move model to device\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # Set maximum number of epochs and patience for early stopping\n",
    "# max_epochs = 40\n",
    "# patience = 5  # Number of epochs with no improvement after which training will stop\n",
    "# best_val_loss = float('inf')  # Initialize best validation loss as infinity\n",
    "# epochs_without_improvement = 0\n",
    "\n",
    "# # Training loop\n",
    "# for epoch in range(max_epochs):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     train_loader = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{max_epochs}\", unit=\"batch\")  # Add tqdm to training loop\n",
    "    \n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to device\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item()\n",
    "#         train_loader.set_postfix(loss=loss.item())  # Update tqdm progress bar with current loss\n",
    "    \n",
    "#     print(f\"Epoch {epoch+1}, Average Loss: {(running_loss / len(train_loader)):.4f}\")\n",
    "\n",
    "#     # Evaluate on the validation dataset\n",
    "#     model.eval()\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     val_loss = 0.0\n",
    "#     with torch.no_grad():  # Disable gradient computation during evaluation\n",
    "#         for images, labels in val_loader:  # Assuming val_loader is the DataLoader for the test/validation set\n",
    "#             images, labels = images.to(device), labels.to(device)\n",
    "#             outputs = model(images)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             val_loss += loss.item()\n",
    "            \n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "    \n",
    "#     avg_val_loss = val_loss / len(val_loader)\n",
    "#     accuracy = 100 * correct / total\n",
    "#     print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "#     print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "#     # Check for early stopping\n",
    "#     if avg_val_loss < best_val_loss:\n",
    "#         best_val_loss = avg_val_loss\n",
    "#         epochs_without_improvement = 0  # Reset counter\n",
    "#     else:\n",
    "#         epochs_without_improvement += 1\n",
    "#         if epochs_without_improvement >= patience:\n",
    "#             print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "#             break  # Stop training early if no improvement\n",
    "\n",
    "#     # Check if we have reached the maximum number of epochs\n",
    "#     if epoch + 1 == max_epochs:\n",
    "#         print(\"Maximum number of epochs reached.\")\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_classes, train_loader, epoch=50):\n",
    "    # Model, loss function, optimizer\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available\n",
    "    # num_classes = len(train_dataset.classes)\n",
    "    # model = SimpleCNN(num_classes=num_classes, image_width=image_width).to(device)  # Move model to device\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Set maximum number of epochs and patience for early stopping\n",
    "    max_epochs = epoch\n",
    "    patience = 5  # Number of epochs with no improvement after which training will stop\n",
    "    best_val_loss = float('inf')  # Initialize best validation loss as infinity\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_loader = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{max_epochs}\", unit=\"batch\")  # Add tqdm to training loop\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to device\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            train_loader.set_postfix(loss=loss.item())  # Update tqdm progress bar with current loss\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Average Loss: {(running_loss / len(train_loader)):.4f}\")\n",
    "\n",
    "        # Evaluate on the validation dataset\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():  # Disable gradient computation during evaluation\n",
    "            for images, labels in val_loader:  # Assuming val_loader is the DataLoader for the test/validation set\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_without_improvement = 0  # Reset counter\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "                break  # Stop training early if no improvement\n",
    "\n",
    "        # Check if we have reached the maximum number of epochs\n",
    "        if epoch + 1 == max_epochs:\n",
    "            print(\"Maximum number of epochs reached.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# # Evaluate on the test dataset with tqdm\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# all_labels = []  # To store true labels\n",
    "# all_preds = []   # To store predicted labels\n",
    "# test_loader = tqdm(test_loader, desc=\"Testing\", unit=\"batch\")  # Add tqdm for the test loop\n",
    "\n",
    "# with torch.no_grad():  # Disable gradient computation during evaluation\n",
    "#     for images, labels in test_loader:  # Loop through test dataset\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "#         outputs = model(images)\n",
    "#         _, predicted = torch.max(outputs, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "        \n",
    "#         all_labels.extend(labels.cpu().numpy())  # Append true labels\n",
    "#         all_preds.extend(predicted.cpu().numpy())  # Append predicted labels\n",
    "        \n",
    "#         # Update tqdm bar with current accuracy\n",
    "#         test_loader.set_postfix(accuracy=(100 * correct / total))  \n",
    "\n",
    "# # Compute test accuracy\n",
    "# test_accuracy = 100 * correct / total\n",
    "\n",
    "# # Compute F1 score for the whole dataset\n",
    "# f1 = f1_score(all_labels, all_preds, average='weighted')  # You can also use 'macro' or 'micro' as needed\n",
    "\n",
    "# print(f\"\\nTest Accuracy: {test_accuracy:.2f}%\")\n",
    "# print(f\"Test F1 Score (Weighted): {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available\n",
    "\n",
    "    # Evaluate on the test dataset with tqdm\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []  # To store true labels\n",
    "    all_preds = []   # To store predicted labels\n",
    "    test_loader = tqdm(test_loader, desc=\"Testing\", unit=\"batch\")  # Add tqdm for the test loop\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation during evaluation\n",
    "        for images, labels in test_loader:  # Loop through test dataset\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())  # Append true labels\n",
    "            all_preds.extend(predicted.cpu().numpy())  # Append predicted labels\n",
    "            \n",
    "            # Update tqdm bar with current accuracy\n",
    "            test_loader.set_postfix(accuracy=(100 * correct / total))  \n",
    "\n",
    "    # Compute test accuracy\n",
    "    test_accuracy = 100 * correct / total\n",
    "\n",
    "    # Compute F1 score for the whole dataset\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')  # You can also use 'macro' or 'micro' as needed\n",
    "\n",
    "    print(f\"\\nTest Accuracy: {test_accuracy:.2f}%\")\n",
    "    print(f\"Test F1 Score (Weighted): {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "def evaluate_model(model, val_loader, class_names):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple CNN Model Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes, image_width):\n",
    "        super(SimpleCNN, self).__init__()  # Call the parent class constructor\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # nn.Conv2d(35, 60, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.BatchNorm2d(60),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Dropout(0.20)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32 * (image_width//4)**2, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.45),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40: 100%|██████████| 1358/1358 [00:11<00:00, 121.96batch/s, loss=0.665]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 1.2995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 80.34%\n",
      "Validation Loss: 0.6502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/40: 100%|██████████| 1358/1358 [00:07<00:00, 180.64batch/s, loss=0.236]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 0.6702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 86.61%\n",
      "Validation Loss: 0.4369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/40: 100%|██████████| 1358/1358 [00:07<00:00, 182.33batch/s, loss=0.38] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Loss: 0.5106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 88.31%\n",
      "Validation Loss: 0.3554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/40: 100%|██████████| 1358/1358 [00:08<00:00, 167.32batch/s, loss=0.151] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average Loss: 0.4136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 90.22%\n",
      "Validation Loss: 0.3023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/40: 100%|██████████| 1358/1358 [00:07<00:00, 177.06batch/s, loss=0.228] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average Loss: 0.3584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 92.06%\n",
      "Validation Loss: 0.2420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/40: 100%|██████████| 1358/1358 [00:07<00:00, 180.00batch/s, loss=0.156] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Average Loss: 0.3110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 91.51%\n",
      "Validation Loss: 0.2559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/40: 100%|██████████| 1358/1358 [00:08<00:00, 162.16batch/s, loss=0.0373]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Average Loss: 0.2758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 93.92%\n",
      "Validation Loss: 0.1899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/40: 100%|██████████| 1358/1358 [00:07<00:00, 179.57batch/s, loss=0.0119] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Average Loss: 0.2474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 93.50%\n",
      "Validation Loss: 0.1889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/40: 100%|██████████| 1358/1358 [00:07<00:00, 175.26batch/s, loss=0.503] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Average Loss: 0.2245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 93.96%\n",
      "Validation Loss: 0.1806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/40: 100%|██████████| 1358/1358 [00:07<00:00, 179.26batch/s, loss=0.237]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Average Loss: 0.2058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 94.38%\n",
      "Validation Loss: 0.1695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/40: 100%|██████████| 1358/1358 [00:08<00:00, 162.54batch/s, loss=0.155] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Average Loss: 0.1908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 93.76%\n",
      "Validation Loss: 0.1943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/40: 100%|██████████| 1358/1358 [00:07<00:00, 179.33batch/s, loss=0.129] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Average Loss: 0.1808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 94.90%\n",
      "Validation Loss: 0.1575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/40: 100%|██████████| 1358/1358 [00:07<00:00, 175.57batch/s, loss=0.214] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Average Loss: 0.1685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 94.05%\n",
      "Validation Loss: 0.1931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/40: 100%|██████████| 1358/1358 [00:07<00:00, 177.31batch/s, loss=0.0383] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Average Loss: 0.1547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 94.57%\n",
      "Validation Loss: 0.1699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/40: 100%|██████████| 1358/1358 [00:08<00:00, 162.74batch/s, loss=0.426]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Average Loss: 0.1495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 95.03%\n",
      "Validation Loss: 0.1562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/40: 100%|██████████| 1358/1358 [00:07<00:00, 176.00batch/s, loss=0.105]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Average Loss: 0.1436\n",
      "Validation Accuracy: 93.37%\n",
      "Validation Loss: 0.2140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/40: 100%|██████████| 1358/1358 [00:07<00:00, 172.25batch/s, loss=0.00826]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Average Loss: 0.1379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 94.59%\n",
      "Validation Loss: 0.1754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/40: 100%|██████████| 1358/1358 [00:07<00:00, 175.62batch/s, loss=0.0868] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Average Loss: 0.1291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 95.08%\n",
      "Validation Loss: 0.1612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/40: 100%|██████████| 1358/1358 [00:07<00:00, 176.17batch/s, loss=0.0217] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Average Loss: 0.1290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 94.94%\n",
      "Validation Loss: 0.1684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/40: 100%|██████████| 1358/1358 [00:07<00:00, 178.11batch/s, loss=0.0588] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Average Loss: 0.1181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 94.81%\n",
      "Validation Loss: 0.1804\n",
      "Early stopping triggered after 20 epochs.\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_dataset.classes)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available\n",
    "model = SimpleCNN(num_classes=num_classes, image_width=image_width).to(device)  # Move model to device\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_model(model, criterion, optimizer, num_classes, train_loader, epoch=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 170/170 [00:01<00:00, 116.78batch/s, accuracy=94.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 94.44%\n",
      "Test F1 Score (Weighted): 0.9434\n"
     ]
    }
   ],
   "source": [
    "test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, val_loader, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to file\n",
    "torch.save(model.state_dict(), 'plant_disease_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Loading from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve model from file \n",
    "model.load_state_dict(torch.load('plant_disease_model.pth'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict single image from external JPG image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load the trained model\n",
    "model.load_state_dict(torch.load('plant_disease_model.pth'))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Define the transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_width, image_width)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = \"test.JPG\"  # Replace with your image path\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "# Perform the prediction\n",
    "with torch.no_grad():\n",
    "    outputs = model(image_tensor)\n",
    "    _, predicted_class = torch.max(outputs, 1)\n",
    "\n",
    "# Map index to class label\n",
    "predicted_label = train_dataset.classes[predicted_class.item()]\n",
    "probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "predicted_prob = probabilities[0, predicted_class].item()\n",
    "\n",
    "print(f\"The predicted class is: {predicted_label} with probability {predicted_prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet Model Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alessio/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/alessio/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "# Caricare ResNet-18 pre-addestrato\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Congelare i layer pre-addestrati\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# Modificare l'ultimo livello fully connected\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Muovere il modello su GPU o CPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss e ottimizzatore\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class to index mapping: {'Apple___Apple_scab': 0, 'Apple___Black_rot': 1, 'Apple___Cedar_apple_rust': 2, 'Apple___healthy': 3, 'Blueberry___healthy': 4, 'Cherry_(including_sour)___Powdery_mildew': 5, 'Cherry_(including_sour)___healthy': 6, 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot': 7, 'Corn_(maize)___Common_rust_': 8, 'Corn_(maize)___Northern_Leaf_Blight': 9, 'Corn_(maize)___healthy': 10, 'Grape___Black_rot': 11, 'Grape___Esca_(Black_Measles)': 12, 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 13, 'Grape___healthy': 14, 'Orange___Haunglongbing_(Citrus_greening)': 15, 'Peach___Bacterial_spot': 16, 'Peach___healthy': 17, 'Pepper,_bell___Bacterial_spot': 18, 'Pepper,_bell___healthy': 19, 'Potato___Early_blight': 20, 'Potato___Late_blight': 21, 'Potato___healthy': 22, 'Raspberry___healthy': 23, 'Soybean___healthy': 24, 'Squash___Powdery_mildew': 25, 'Strawberry___Leaf_scorch': 26, 'Strawberry___healthy': 27, 'Tomato___Bacterial_spot': 28, 'Tomato___Early_blight': 29, 'Tomato___Late_blight': 30, 'Tomato___Leaf_Mold': 31, 'Tomato___Septoria_leaf_spot': 32, 'Tomato___Spider_mites Two-spotted_spider_mite': 33, 'Tomato___Target_Spot': 34, 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 35, 'Tomato___Tomato_mosaic_virus': 36, 'Tomato___healthy': 37}\n",
      "                                                Class  Count\n",
      "0                                    Potato___healthy    121\n",
      "1                            Apple___Cedar_apple_rust    220\n",
      "2                                     Peach___healthy    288\n",
      "3                                 Raspberry___healthy    297\n",
      "4                        Tomato___Tomato_mosaic_virus    299\n",
      "5                                     Grape___healthy    339\n",
      "6                                Strawberry___healthy    364\n",
      "7   Corn_(maize)___Cercospora_leaf_spot Gray_leaf_...    410\n",
      "8                                   Apple___Black_rot    496\n",
      "9                                  Apple___Apple_scab    504\n",
      "10                  Cherry_(including_sour)___healthy    684\n",
      "11                                 Tomato___Leaf_Mold    761\n",
      "12                Corn_(maize)___Northern_Leaf_Blight    788\n",
      "13                      Pepper,_bell___Bacterial_spot    797\n",
      "14                               Potato___Late_blight    800\n",
      "15                              Potato___Early_blight    800\n",
      "16                              Tomato___Early_blight    800\n",
      "17           Cherry_(including_sour)___Powdery_mildew    842\n",
      "18         Grape___Leaf_blight_(Isariopsis_Leaf_Spot)    861\n",
      "19                           Strawberry___Leaf_scorch    887\n",
      "20                             Corn_(maize)___healthy    929\n",
      "21                                  Grape___Black_rot    944\n",
      "22                        Corn_(maize)___Common_rust_    953\n",
      "23                       Grape___Esca_(Black_Measles)   1107\n",
      "24                               Tomato___Target_Spot   1123\n",
      "25                             Pepper,_bell___healthy   1183\n",
      "26                                Blueberry___healthy   1202\n",
      "27                                   Tomato___healthy   1273\n",
      "28                                    Apple___healthy   1316\n",
      "29      Tomato___Spider_mites Two-spotted_spider_mite   1341\n",
      "30                        Tomato___Septoria_leaf_spot   1417\n",
      "31                            Squash___Powdery_mildew   1468\n",
      "32                               Tomato___Late_blight   1527\n",
      "33                            Tomato___Bacterial_spot   1702\n",
      "34                             Peach___Bacterial_spot   1838\n",
      "35                                  Soybean___healthy   4072\n",
      "36             Tomato___Tomato_Yellow_Leaf_Curl_Virus   4286\n",
      "37           Orange___Haunglongbing_(Citrus_greening)   4405\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Define transformations for your dataset\n",
    "image_width = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_width, image_width)),  # Resize all images to 128x128\n",
    "    transforms.ToTensor(),          # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Load train dataset\n",
    "train_path = os.path.join('PlantVillage', 'train')\n",
    "train_dataset = datasets.ImageFolder(root=train_path, transform=transform)\n",
    "\n",
    "# Load val dataset\n",
    "val_path = os.path.join('PlantVillage', 'val')\n",
    "val_dataset = datasets.ImageFolder(root=val_path, transform=transform)\n",
    "\n",
    "# Split val dataset into val and test\n",
    "test_split = 0.5  # Use 50% of the current val set as the test set\n",
    "test_size = int(test_split * len(val_dataset))\n",
    "val_size = len(val_dataset) - test_size\n",
    "\n",
    "val_dataset, test_dataset = random_split(val_dataset, [val_size, test_size])\n",
    "\n",
    "# Create DataLoaders for train, val, and test datasets\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Function to count class instances with a progress bar\n",
    "def count_classes(dataset):\n",
    "    class_counter = Counter()\n",
    "    for _, label in tqdm(dataset, desc=\"Counting classes\"):\n",
    "        class_counter[label] += 1\n",
    "    return class_counter\n",
    "\n",
    "# Access class-to-index mapping\n",
    "class_to_idx = train_dataset.class_to_idx\n",
    "print(\"Class to index mapping:\", class_to_idx)\n",
    "\n",
    "def count_classes_in_folders(dataset_path):\n",
    "    \"\"\"\n",
    "    Count the number of items in each class folder in the dataset.\n",
    "    \"\"\"\n",
    "    class_counts = {}\n",
    "    for class_name in os.listdir(dataset_path):\n",
    "        class_folder = os.path.join(dataset_path, class_name)\n",
    "        if os.path.isdir(class_folder):  # Ensure it's a directory\n",
    "            class_counts[class_name] = len(os.listdir(class_folder))\n",
    "    return class_counts\n",
    "\n",
    "# Count classes\n",
    "train_class_counts = count_classes_in_folders(train_path)\n",
    "\n",
    "# Create a DataFrame from the train_class_counts dictionary\n",
    "class_df = pd.DataFrame(list(train_class_counts.items()), columns=[\"Class\", \"Count\"])\n",
    "\n",
    "# Sort the DataFrame by 'Count' in ascending order\n",
    "class_df_sorted = class_df.sort_values(by=\"Count\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Print the sorted DataFrame\n",
    "print(class_df_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 1358/1358 [01:11<00:00, 18.93batch/s, loss=0.386] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 0.5714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 93.67%\n",
      "Validation Loss: 0.2324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 1358/1358 [01:07<00:00, 20.20batch/s, loss=0.22]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 0.2252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 94.55%\n",
      "Validation Loss: 0.1739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 1358/1358 [01:10<00:00, 19.39batch/s, loss=0.179] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Loss: 0.1724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 95.32%\n",
      "Validation Loss: 0.1481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 1358/1358 [01:07<00:00, 20.07batch/s, loss=0.0503]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average Loss: 0.1491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 95.53%\n",
      "Validation Loss: 0.1315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 1358/1358 [01:06<00:00, 20.43batch/s, loss=0.11]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average Loss: 0.1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 96.34%\n",
      "Validation Loss: 0.1163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 1358/1358 [01:01<00:00, 22.10batch/s, loss=0.201]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Average Loss: 0.1192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 95.80%\n",
      "Validation Loss: 0.1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 1358/1358 [01:02<00:00, 21.62batch/s, loss=0.0226] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Average Loss: 0.1134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 96.19%\n",
      "Validation Loss: 0.1124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 1358/1358 [01:01<00:00, 21.91batch/s, loss=0.0631] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Average Loss: 0.1038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 96.21%\n",
      "Validation Loss: 0.1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 1358/1358 [01:03<00:00, 21.50batch/s, loss=0.0553] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Average Loss: 0.1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 96.43%\n",
      "Validation Loss: 0.1016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 1358/1358 [01:05<00:00, 20.80batch/s, loss=0.157]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Average Loss: 0.0955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 96.43%\n",
      "Validation Loss: 0.1125\n",
      "Maximum number of epochs reached.\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "train_model(model, criterion, optimizer, num_classes, train_loader, epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Evaluate on the test dataset with tqdm\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "all_labels = []  # To store true labels\n",
    "all_preds = []   # To store predicted labels\n",
    "test_loader = tqdm(test_loader, desc=\"Testing\", unit=\"batch\")  # Add tqdm for the test loop\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation during evaluation\n",
    "    for images, labels in test_loader:  # Loop through test dataset\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy())  # Append true labels\n",
    "        all_preds.extend(predicted.cpu().numpy())  # Append predicted labels\n",
    "        \n",
    "        # Update tqdm bar with current accuracy\n",
    "        test_loader.set_postfix(accuracy=(100 * correct / total))  \n",
    "\n",
    "# Compute test accuracy\n",
    "test_accuracy = 100 * correct / total\n",
    "\n",
    "# Compute F1 score for the whole dataset\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')  # You can also use 'macro' or 'micro' as needed\n",
    "\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"Test F1 Score (Weighted): {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.classes\n",
    "evaluate_model(model, val_loader, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'resNet_plant_disease_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 predicted classes:\n",
      "1. Apple___Cedar_apple_rust: 0.3975\n",
      "2. Grape___Esca_(Black_Measles): 0.3141\n",
      "3. Strawberry___Leaf_scorch: 0.2657\n",
      "4. Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot: 0.0076\n",
      "5. Apple___Black_rot: 0.0067\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load the trained model\n",
    "model.load_state_dict(torch.load('resNet_plant_disease_model.pth'))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "image_width = 224\n",
    "\n",
    "# Define the transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_width, image_width)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = \"/home/alessio/FDS-Project/anotherTask.jpg\"  # Replace with your image path\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "# Perform the prediction\n",
    "with torch.no_grad():\n",
    "    outputs = model(image_tensor)\n",
    "    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "    top3_prob, top3_classes = torch.topk(probabilities, 5)  # Get top 3 probabilities and class indices\n",
    "\n",
    "# Print the top 3 classes and their probabilities\n",
    "print(\"Top 3 predicted classes:\")\n",
    "for i in range(5):\n",
    "    class_index = top3_classes[0, i].item()\n",
    "    class_label = train_dataset.classes[class_index]\n",
    "    class_prob = top3_prob[0, i].item()\n",
    "    print(f\"{i+1}. {class_label}: {class_prob:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
