{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Torch with CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True if GPU is available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class to index mapping: {'Apple___Apple_scab': 0, 'Apple___Black_rot': 1, 'Apple___Cedar_apple_rust': 2, 'Apple___healthy': 3, 'Blueberry___healthy': 4, 'Cherry_(including_sour)___Powdery_mildew': 5, 'Cherry_(including_sour)___healthy': 6, 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot': 7, 'Corn_(maize)___Common_rust_': 8, 'Corn_(maize)___Northern_Leaf_Blight': 9, 'Corn_(maize)___healthy': 10, 'Grape___Black_rot': 11, 'Grape___Esca_(Black_Measles)': 12, 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 13, 'Grape___healthy': 14, 'Orange___Haunglongbing_(Citrus_greening)': 15, 'Peach___Bacterial_spot': 16, 'Peach___healthy': 17, 'Pepper,_bell___Bacterial_spot': 18, 'Pepper,_bell___healthy': 19, 'Potato___Early_blight': 20, 'Potato___Late_blight': 21, 'Potato___healthy': 22, 'Raspberry___healthy': 23, 'Soybean___healthy': 24, 'Squash___Powdery_mildew': 25, 'Strawberry___Leaf_scorch': 26, 'Strawberry___healthy': 27, 'Tomato___Bacterial_spot': 28, 'Tomato___Early_blight': 29, 'Tomato___Late_blight': 30, 'Tomato___Leaf_Mold': 31, 'Tomato___Septoria_leaf_spot': 32, 'Tomato___Spider_mites Two-spotted_spider_mite': 33, 'Tomato___Target_Spot': 34, 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 35, 'Tomato___Tomato_mosaic_virus': 36, 'Tomato___healthy': 37}\n",
      "                                                Class  Count\n",
      "0                                    Potato___healthy    121\n",
      "1                            Apple___Cedar_apple_rust    220\n",
      "2                                     Peach___healthy    288\n",
      "3                                 Raspberry___healthy    297\n",
      "4                        Tomato___Tomato_mosaic_virus    299\n",
      "5                                     Grape___healthy    339\n",
      "6                                Strawberry___healthy    364\n",
      "7   Corn_(maize)___Cercospora_leaf_spot Gray_leaf_...    410\n",
      "8                                   Apple___Black_rot    496\n",
      "9                                  Apple___Apple_scab    504\n",
      "10                  Cherry_(including_sour)___healthy    684\n",
      "11                                 Tomato___Leaf_Mold    761\n",
      "12                Corn_(maize)___Northern_Leaf_Blight    788\n",
      "13                      Pepper,_bell___Bacterial_spot    797\n",
      "14                               Potato___Late_blight    800\n",
      "15                              Tomato___Early_blight    800\n",
      "16                              Potato___Early_blight    800\n",
      "17           Cherry_(including_sour)___Powdery_mildew    842\n",
      "18         Grape___Leaf_blight_(Isariopsis_Leaf_Spot)    861\n",
      "19                           Strawberry___Leaf_scorch    887\n",
      "20                             Corn_(maize)___healthy    929\n",
      "21                                  Grape___Black_rot    944\n",
      "22                        Corn_(maize)___Common_rust_    953\n",
      "23                       Grape___Esca_(Black_Measles)   1107\n",
      "24                               Tomato___Target_Spot   1123\n",
      "25                             Pepper,_bell___healthy   1183\n",
      "26                                Blueberry___healthy   1202\n",
      "27                                   Tomato___healthy   1273\n",
      "28                                    Apple___healthy   1316\n",
      "29      Tomato___Spider_mites Two-spotted_spider_mite   1341\n",
      "30                        Tomato___Septoria_leaf_spot   1417\n",
      "31                            Squash___Powdery_mildew   1468\n",
      "32                               Tomato___Late_blight   1527\n",
      "33                            Tomato___Bacterial_spot   1702\n",
      "34                             Peach___Bacterial_spot   1838\n",
      "35                                  Soybean___healthy   4072\n",
      "36             Tomato___Tomato_Yellow_Leaf_Curl_Virus   4286\n",
      "37           Orange___Haunglongbing_(Citrus_greening)   4405\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Define transformations for your dataset\n",
    "image_width = 32\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_width, image_width)),  # Resize all images to 128x128\n",
    "    transforms.ToTensor(),          # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Load train dataset\n",
    "train_path = os.path.join('PlantVillage', 'train')\n",
    "train_dataset = datasets.ImageFolder(root=train_path, transform=transform)\n",
    "\n",
    "# Load val dataset\n",
    "val_path = os.path.join('PlantVillage', 'val')\n",
    "val_dataset = datasets.ImageFolder(root=val_path, transform=transform)\n",
    "\n",
    "# Split val dataset into val and test\n",
    "test_split = 0.5  # Use 50% of the current val set as the test set\n",
    "test_size = int(test_split * len(val_dataset))\n",
    "val_size = len(val_dataset) - test_size\n",
    "\n",
    "val_dataset, test_dataset = random_split(val_dataset, [val_size, test_size])\n",
    "\n",
    "# Create DataLoaders for train, val, and test datasets\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Function to count class instances with a progress bar\n",
    "def count_classes(dataset):\n",
    "    class_counter = Counter()\n",
    "    for _, label in tqdm(dataset, desc=\"Counting classes\"):\n",
    "        class_counter[label] += 1\n",
    "    return class_counter\n",
    "\n",
    "# Access class-to-index mapping\n",
    "class_to_idx = train_dataset.class_to_idx\n",
    "print(\"Class to index mapping:\", class_to_idx)\n",
    "\n",
    "def count_classes_in_folders(dataset_path):\n",
    "    \"\"\"\n",
    "    Count the number of items in each class folder in the dataset.\n",
    "    \"\"\"\n",
    "    class_counts = {}\n",
    "    for class_name in os.listdir(dataset_path):\n",
    "        class_folder = os.path.join(dataset_path, class_name)\n",
    "        if os.path.isdir(class_folder):  # Ensure it's a directory\n",
    "            class_counts[class_name] = len(os.listdir(class_folder))\n",
    "    return class_counts\n",
    "\n",
    "# Count classes\n",
    "train_class_counts = count_classes_in_folders(train_path)\n",
    "\n",
    "# Create a DataFrame from the train_class_counts dictionary\n",
    "class_df = pd.DataFrame(list(train_class_counts.items()), columns=[\"Class\", \"Count\"])\n",
    "\n",
    "# Sort the DataFrame by 'Count' in ascending order\n",
    "class_df_sorted = class_df.sort_values(by=\"Count\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Print the sorted DataFrame\n",
    "print(class_df_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes, image_width):\n",
    "        super(SimpleCNN, self).__init__()  # Call the parent class constructor\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # nn.Conv2d(35, 60, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.BatchNorm2d(60),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Dropout(0.20)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32 * (image_width//4)**2, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.45),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40:   0%|          | 0/1358 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40: 100%|██████████| 1358/1358 [00:56<00:00, 23.90batch/s, loss=0.911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 1.3081\n",
      "Validation Accuracy: 80.67%\n",
      "Validation Loss: 0.6176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/40: 100%|██████████| 1358/1358 [00:56<00:00, 24.22batch/s, loss=1.1]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 0.6652\n",
      "Validation Accuracy: 86.25%\n",
      "Validation Loss: 0.4423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/40: 100%|██████████| 1358/1358 [00:57<00:00, 23.62batch/s, loss=0.382] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Loss: 0.5061\n",
      "Validation Accuracy: 86.95%\n",
      "Validation Loss: 0.3969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/40: 100%|██████████| 1358/1358 [00:57<00:00, 23.82batch/s, loss=0.35]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average Loss: 0.4166\n",
      "Validation Accuracy: 89.95%\n",
      "Validation Loss: 0.3031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/40: 100%|██████████| 1358/1358 [00:57<00:00, 23.56batch/s, loss=0.352] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average Loss: 0.3558\n",
      "Validation Accuracy: 91.68%\n",
      "Validation Loss: 0.2568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/40: 100%|██████████| 1358/1358 [00:56<00:00, 23.90batch/s, loss=0.121] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Average Loss: 0.3148\n",
      "Validation Accuracy: 90.52%\n",
      "Validation Loss: 0.2713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/40: 100%|██████████| 1358/1358 [00:54<00:00, 24.85batch/s, loss=0.585] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Average Loss: 0.2777\n",
      "Validation Accuracy: 92.10%\n",
      "Validation Loss: 0.2416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/40: 100%|██████████| 1358/1358 [00:51<00:00, 26.44batch/s, loss=0.0628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Average Loss: 0.2612\n",
      "Validation Accuracy: 91.94%\n",
      "Validation Loss: 0.2455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/40: 100%|██████████| 1358/1358 [00:51<00:00, 26.49batch/s, loss=0.0633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Average Loss: 0.2315\n",
      "Validation Accuracy: 93.41%\n",
      "Validation Loss: 0.1961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/40: 100%|██████████| 1358/1358 [00:48<00:00, 27.99batch/s, loss=0.239] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Average Loss: 0.2157\n",
      "Validation Accuracy: 93.68%\n",
      "Validation Loss: 0.1935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/40: 100%|██████████| 1358/1358 [00:49<00:00, 27.53batch/s, loss=0.118] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Average Loss: 0.2037\n",
      "Validation Accuracy: 94.02%\n",
      "Validation Loss: 0.1871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/40: 100%|██████████| 1358/1358 [00:57<00:00, 23.61batch/s, loss=0.667] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Average Loss: 0.1827\n",
      "Validation Accuracy: 93.67%\n",
      "Validation Loss: 0.2107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/40: 100%|██████████| 1358/1358 [00:51<00:00, 26.12batch/s, loss=0.137]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Average Loss: 0.1763\n",
      "Validation Accuracy: 94.22%\n",
      "Validation Loss: 0.1890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/40: 100%|██████████| 1358/1358 [00:54<00:00, 25.03batch/s, loss=0.23]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Average Loss: 0.1696\n",
      "Validation Accuracy: 93.52%\n",
      "Validation Loss: 0.2051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/40: 100%|██████████| 1358/1358 [00:49<00:00, 27.42batch/s, loss=0.0751] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Average Loss: 0.1593\n",
      "Validation Accuracy: 94.49%\n",
      "Validation Loss: 0.1833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/40: 100%|██████████| 1358/1358 [00:47<00:00, 28.67batch/s, loss=0.0851] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Average Loss: 0.1539\n",
      "Validation Accuracy: 94.22%\n",
      "Validation Loss: 0.1840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/40: 100%|██████████| 1358/1358 [00:47<00:00, 28.55batch/s, loss=0.265]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Average Loss: 0.1462\n",
      "Validation Accuracy: 94.33%\n",
      "Validation Loss: 0.1843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/40: 100%|██████████| 1358/1358 [00:48<00:00, 28.24batch/s, loss=0.145]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Average Loss: 0.1417\n",
      "Validation Accuracy: 93.87%\n",
      "Validation Loss: 0.1959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/40: 100%|██████████| 1358/1358 [00:48<00:00, 28.17batch/s, loss=0.081]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Average Loss: 0.1349\n",
      "Validation Accuracy: 94.35%\n",
      "Validation Loss: 0.1879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/40: 100%|██████████| 1358/1358 [00:51<00:00, 26.12batch/s, loss=0.013]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Average Loss: 0.1338\n",
      "Validation Accuracy: 94.40%\n",
      "Validation Loss: 0.1783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/40: 100%|██████████| 1358/1358 [00:50<00:00, 27.15batch/s, loss=0.00734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Average Loss: 0.1224\n",
      "Validation Accuracy: 94.68%\n",
      "Validation Loss: 0.1842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/40: 100%|██████████| 1358/1358 [00:47<00:00, 28.76batch/s, loss=0.106]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Average Loss: 0.1195\n",
      "Validation Accuracy: 94.02%\n",
      "Validation Loss: 0.2139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/40: 100%|██████████| 1358/1358 [00:46<00:00, 29.41batch/s, loss=0.168]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Average Loss: 0.1156\n",
      "Validation Accuracy: 95.18%\n",
      "Validation Loss: 0.1669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/40: 100%|██████████| 1358/1358 [00:45<00:00, 29.54batch/s, loss=0.0186] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Average Loss: 0.1125\n",
      "Validation Accuracy: 94.31%\n",
      "Validation Loss: 0.2061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/40: 100%|██████████| 1358/1358 [00:46<00:00, 29.12batch/s, loss=0.0893] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Average Loss: 0.1085\n",
      "Validation Accuracy: 94.68%\n",
      "Validation Loss: 0.1899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/40: 100%|██████████| 1358/1358 [00:47<00:00, 28.62batch/s, loss=0.47]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Average Loss: 0.1112\n",
      "Validation Accuracy: 94.73%\n",
      "Validation Loss: 0.1887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/40: 100%|██████████| 1358/1358 [00:45<00:00, 29.84batch/s, loss=0.0145]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Average Loss: 0.1080\n",
      "Validation Accuracy: 95.01%\n",
      "Validation Loss: 0.1874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/40: 100%|██████████| 1358/1358 [00:47<00:00, 28.44batch/s, loss=0.00976] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Average Loss: 0.1000\n",
      "Validation Accuracy: 95.56%\n",
      "Validation Loss: 0.1667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/40: 100%|██████████| 1358/1358 [00:46<00:00, 29.03batch/s, loss=0.0831]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Average Loss: 0.0982\n",
      "Validation Accuracy: 95.12%\n",
      "Validation Loss: 0.1864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/40: 100%|██████████| 1358/1358 [00:47<00:00, 28.53batch/s, loss=0.0233] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Average Loss: 0.1029\n",
      "Validation Accuracy: 95.03%\n",
      "Validation Loss: 0.1881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/40: 100%|██████████| 1358/1358 [00:47<00:00, 28.74batch/s, loss=0.00262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Average Loss: 0.0986\n",
      "Validation Accuracy: 95.43%\n",
      "Validation Loss: 0.1724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/40: 100%|██████████| 1358/1358 [00:46<00:00, 29.07batch/s, loss=0.0166]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Average Loss: 0.0991\n",
      "Validation Accuracy: 94.88%\n",
      "Validation Loss: 0.1970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/40: 100%|██████████| 1358/1358 [00:50<00:00, 27.10batch/s, loss=0.231]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Average Loss: 0.0904\n",
      "Validation Accuracy: 95.14%\n",
      "Validation Loss: 0.1825\n",
      "Early stopping triggered after 33 epochs.\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Model, loss function, optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available\n",
    "num_classes = len(train_dataset.classes)\n",
    "model = SimpleCNN(num_classes=num_classes, image_width=image_width).to(device)  # Move model to device\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Set maximum number of epochs and patience for early stopping\n",
    "max_epochs = 40\n",
    "patience = 5  # Number of epochs with no improvement after which training will stop\n",
    "best_val_loss = float('inf')  # Initialize best validation loss as infinity\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_loader = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{max_epochs}\", unit=\"batch\")  # Add tqdm to training loop\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to device\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        train_loader.set_postfix(loss=loss.item())  # Update tqdm progress bar with current loss\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Average Loss: {(running_loss / len(train_loader)):.4f}\")\n",
    "\n",
    "    # Evaluate on the validation dataset\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():  # Disable gradient computation during evaluation\n",
    "        for images, labels in val_loader:  # Assuming val_loader is the DataLoader for the test/validation set\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "    # Check for early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0  # Reset counter\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break  # Stop training early if no improvement\n",
    "\n",
    "    # Check if we have reached the maximum number of epochs\n",
    "    if epoch + 1 == max_epochs:\n",
    "        print(\"Maximum number of epochs reached.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 170/170 [00:23<00:00,  7.30batch/s, accuracy=95.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 95.43%\n",
      "Test F1 Score (Weighted): 0.9539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Evaluate on the test dataset with tqdm\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "all_labels = []  # To store true labels\n",
    "all_preds = []   # To store predicted labels\n",
    "test_loader = tqdm(test_loader, desc=\"Testing\", unit=\"batch\")  # Add tqdm for the test loop\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation during evaluation\n",
    "    for images, labels in test_loader:  # Loop through test dataset\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy())  # Append true labels\n",
    "        all_preds.extend(predicted.cpu().numpy())  # Append predicted labels\n",
    "        \n",
    "        # Update tqdm bar with current accuracy\n",
    "        test_loader.set_postfix(accuracy=(100 * correct / total))  \n",
    "\n",
    "# Compute test accuracy\n",
    "test_accuracy = 100 * correct / total\n",
    "\n",
    "# Compute F1 score for the whole dataset\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')  # You can also use 'macro' or 'micro' as needed\n",
    "\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"Test F1 Score (Weighted): {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
